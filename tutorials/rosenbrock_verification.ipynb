{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f73748-69b4-4400-8b96-31063ceebc65",
   "metadata": {},
   "source": [
    "# NN surrogate for the Rosenbrock function\n",
    "\n",
    "This notebook provides an example of training a neural network as a surrogate model to an analytic function, and running the Airobas verification pipeline to determine the stability of the trained model.\n",
    "\n",
    "We use the [Rosenbrock function](https://fr.wikipedia.org/wiki/Fonction_de_Rosenbrock) as our toy use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f386d8f-81a9-4d5c-9176-579c2e306107",
   "metadata": {},
   "source": [
    "## Mathematical definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e778e",
   "metadata": {},
   "source": [
    "The Rosenbrock function is a N-dimentional non-convex function such that:\n",
    "$$\n",
    "f(\\mathbf{x}) = \\sum_{i=1}^{N-1} 100 (x_{i+1} - x_i^2 )^2 + (1-x_i)^2 \\quad \\text{where} \\quad \\mathbf{x} = [x_1, \\ldots, x_N] \\in \\mathbb{R}^N.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815221c9",
   "metadata": {},
   "source": [
    "## SMT library\n",
    "\n",
    "For the surrogate model training step, we also encourage people to look at the surrogate modeling toolbox ([SMT](https://github.com/SMTorg/smt/blob/master/tutorial/SMT_Tutorial.ipynb)) and tutorials that provides a range of surrogate options on the same function.\n",
    "\n",
    "Some utilities function used in this tutorial are borrowed from this SMT library e.g., the creation of training/testing dataset or the 3D plotting stage, directly adapted from the code of the SMT tutorial. Special thanks to SMT creators for their agreement for us to reuse the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b941352",
   "metadata": {},
   "source": [
    "## Usefull Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")  # Import the airobas lib, edit the path accordingly if needed.\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "import random\n",
    "\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from rosenbrock_verification import decomon_computation, image_dump_folder\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e848f6-f967-40c0-8b12-ff84b1931b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot routine\n",
    "\n",
    "\n",
    "def plot_3d(xt, yt, xtest, ytest, fun, name_figure=\"Rosenbrock\"):\n",
    "    x = np.linspace(-2, 2, 50)\n",
    "    res = []\n",
    "    for x0 in x:\n",
    "        for x1 in x:\n",
    "            res.append(fun(np.array([[x0, x1]])))\n",
    "    res = np.array(res)\n",
    "    res = res.reshape((50, 50)).T\n",
    "    X, Y = np.meshgrid(x, x)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    surf = ax.plot_surface(X, Y, res, cmap=matplotlib.colormaps[\"viridis\"], linewidth=0, antialiased=False, alpha=0.5)\n",
    "    if xt is not None:\n",
    "        ax.scatter(xt[:, 0], xt[:, 1], yt, zdir=\"z\", marker=\"x\", c=\"b\", s=200, label=\"Training point\")\n",
    "    if xtest is not None:\n",
    "        ax.scatter(xtest[:, 0], xtest[:, 1], ytest, zdir=\"z\", marker=\".\", c=\"k\", s=200, label=\"Validation point\")\n",
    "    ax.set_title(name_figure)\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smt.problems import Rosenbrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303e915-8b0b-4e0e-8608-e8fb83d9ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d(None, None, None, None, Rosenbrock(ndim=2))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cfe45-37cc-4b35-8599-0b0886899cf0",
   "metadata": {},
   "source": [
    "## Training a neural network as surrogate to the Rosenbrock function\n",
    "\n",
    "### Data generation\n",
    "\n",
    "In order to train the neural network, we first create a training and testing dataset. \n",
    "\n",
    "We implement 2 different methods to build these dataset:\n",
    "\n",
    "- A basic grid-based solution and\n",
    "- One based on Latin Hypercube Sampling (LHS; see SMT documentation [here](https://smt.readthedocs.io/en/latest/_src_docs/sampling_methods/lhs.html)) to generate quasi-random sampling distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid-based sampling\n",
    "\n",
    "\n",
    "def create_points_grid(grid_size: int = 51, fraction_training: float = 0.2):\n",
    "    fun = Rosenbrock(ndim=2)\n",
    "    x = np.linspace(-2, 2, grid_size)\n",
    "    res = []\n",
    "    points = []\n",
    "    for x0 in x:\n",
    "        for x1 in x:\n",
    "            res.append(fun(np.array([[x0, x1]])))\n",
    "            points.append([x0, x1])\n",
    "    random_indexes = set(random.sample(range(len(points)), k=int(fraction_training * len(points))))\n",
    "    xt = np.array([points[i] for i in random_indexes])\n",
    "    yt = np.array([res[i] for i in random_indexes])\n",
    "    xtest = np.array([points[i] for i in range(len(points)) if i not in random_indexes])\n",
    "    ytest = np.array([res[i][0] for i in range(len(points)) if i not in random_indexes])\n",
    "    return xt, yt, xtest, ytest, fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa63e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smt.sampling_methods import LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bf57a-ebf6-4234-921b-9fa12faf649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LHS-based sampling\n",
    "\n",
    "\n",
    "def create_points(n_training: int = 20, n_test=200):\n",
    "    ########### Initialization of the problem, construction of the training and validation points\n",
    "    ndim = 2\n",
    "    n_training = n_training\n",
    "    # Define the function\n",
    "    fun = Rosenbrock(ndim=ndim)\n",
    "    # Construction of the DOE\n",
    "    # in order to have the always same LHS points, random_state=1\n",
    "    sampling = LHS(xlimits=fun.xlimits, criterion=\"ese\", random_state=1)\n",
    "    xt = sampling(n_training)\n",
    "    # Compute the outputs\n",
    "    yt = fun(xt)\n",
    "    # Construction of the validation points\n",
    "    n_test = n_test\n",
    "    sampling = LHS(xlimits=fun.xlimits, criterion=\"ese\", random_state=1)\n",
    "    xtest = sampling(n_test)\n",
    "    ytest = fun(xtest)\n",
    "    return xt, yt, xtest, ytest, fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5992c47-e9fd-4091-b7f7-456e2b0162f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_g, yt_g, xtest_g, ytest_g, fun = create_points_grid(grid_size=51, fraction_training=0.2)\n",
    "xt_lhs, yt_lhs, xtest_lhs, ytest_lhs, fun = create_points(n_training=100, n_test=500)\n",
    "\n",
    "for xt, xtest, tag in [(xt_g, xtest_g, \"grid\"), (xt_lhs, xtest_lhs, \"Latin Hypercube\")]:\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(xt[:, 0], xt[:, 1], marker=\"x\", c=\"b\", s=50, label=\"Training points\")\n",
    "    plt.scatter(xtest[:, 0], xtest[:, 1], marker=\".\", c=\"k\", s=50, label=\"Testing points\")\n",
    "    plt.title(f\"Training & testing points with {tag} sampling\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112623b-55bb-4b6d-9b97-6ca6e1a943bb",
   "metadata": {},
   "source": [
    "### Training a feedforward neural network\n",
    "\n",
    "We train a feedforward model with a few ReLu and a final linear layer. \n",
    "\n",
    "We note that the choice of the number of activation neurons and layers were here taken arbitrary and could be optimized for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac2b52-bc90-4616-aaa0-1493b4bab59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xt, yt, xtest, ytest, nb_epoch: int = 5000):\n",
    "    np.random.seed(42)\n",
    "    # Define the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, activation=\"relu\"))  # , kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, activation=\"relu\"))  # , kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, activation=\"relu\"))  # , kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, activation=\"relu\"))  # , kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(xt, yt, epochs=nb_epoch, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "    print(\"Training loss over epochs:\")\n",
    "    print(history.history[\"loss\"])\n",
    "\n",
    "    print(\"Validation loss over epochs:\")\n",
    "    print(history.history[\"val_loss\"])\n",
    "\n",
    "    y_pred = model.predict(xtest)\n",
    "    test_loss = root_mean_squared_error(ytest, y_pred)\n",
    "    print(\"Test Loss (Root Mean Squared Error):\", test_loss)\n",
    "    print()\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab182f97-1021-4b5d-9c8c-589391f00a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred = train_model(xt_g, yt_g, xtest_g, ytest_g, nb_epoch=300)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a14913-b9ce-429d-ac98-6999f00c815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0f9ab-eac4-453f-a51a-86c9bde2dc42",
   "metadata": {},
   "source": [
    "## Local stability analysis\n",
    "\n",
    "In the present study, the concept of local stability refers to how much the predicted values vary in a immediate neighborhood of a given test point. \n",
    "\n",
    "In real-life applications, system and safety requirements may impose that for two points close in values in the input space (e.g., a reference test point and a point generated from this reference point by perturbating it by a small input noise), the difference in the model predicted values stays within a given stability range.\n",
    "\n",
    "We wish to assess and hopefully guarantee this local stability property for the neural network surrogate of the Rosenbrook function.\n",
    "\n",
    "### Surrogate lower and upper bounds obtained via abstract interpretation method\n",
    "\n",
    "We derive lower and upper bound estimates of the prediction for a set of grid point (using the rosenbrock_example.decomon_computation script).\n",
    "\n",
    "The default values for the allowed input noise in a $L_{\\infty}$ box of +/- 0.1 on each input dimension.\n",
    "The default method used to derive bounds is [CROWN](https://github.com/IBM/CROWN-Robustness-Certification), implemented in the open-source library [decomon](https://github.com/airbus/decomon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d05c6-adeb-4b5d-9bb9-c65a5751e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomon_computation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee58373-d55f-4490-8c49-7c5624f2b129",
   "metadata": {},
   "source": [
    "We invite you to have a look at the ```images/``` folder where a number of analysis plots are saved.\n",
    "\n",
    "The following figures shows the $x1 = 0.0$, $x1 = 2.0$, $x2 = 0.0$, $x2 = 0.0$ slices respectively for the Rosenbrook function, surrogate model as well as estimated upper and lower bounds. \n",
    "\n",
    "![im](rosenbrock_images/slice_x1eq0.0.png)\n",
    "![im](rosenbrock_images/slice_x1eq2.0.png)\n",
    "![im](rosenbrock_images/slice_x2eq0.0.png)\n",
    "![im](rosenbrock_images/slice_x2eq2.0.png)\n",
    "\n",
    "<div class=\"alert alert-warning\">If images not rendered (see slice_x1eq0.0.png, slice_x1eq2.0.png, slice_x2eq0.0.png and slice_x2eq2.0.png in the \"images\" folder)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f9ae-0ee4-4c58-b5f0-510a93ed8eac",
   "metadata": {},
   "source": [
    "These results provide insights in the model stability (or lack of). The visualisations allow the identification of areas where the lower and upper bounds on the output might be too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c934-029e-494a-b167-12967747a978",
   "metadata": {},
   "source": [
    "### Stability property assessment using a combinaison of verification techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227999e-1a73-487d-985d-491480b413b2",
   "metadata": {},
   "source": [
    "##### Defining the problem container\n",
    "\n",
    "Let's start by defining the stability property we want to assess/guarantee.\n",
    "Here, we will consider: \n",
    "\n",
    "- an input perturbation of +/- ```abs_noise_input``` for each tested input point (x1,x2)\n",
    "- a stability property depending on the predicted output value range $pred$:\n",
    "     - if $abs(pred)\\leq $ ```threshold_for_abs_noise```: the \"stable\" output range is [$pred$-```abs_noise_output```, $pred$+```abs_noise_output```]\n",
    "     - else: the \"stable\" output range is [$pred$ - ```rel_noise_output```.abs($pred$), $pred$+```rel_noise_output```.abs($pred$)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff38975-5f74-4c4b-8b99-49a8932e8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airobas.verif_pipeline import (\n",
    "    BoundsDomainBoxParameter,\n",
    "    BoundsDomainBoxParameterPerValueInterval,\n",
    "    ProblemContainer,\n",
    ")\n",
    "\n",
    "\n",
    "class RosenbrockContainer(ProblemContainer):\n",
    "    @staticmethod\n",
    "    def create_rosenbrock_container(\n",
    "        model: keras.Model,\n",
    "        abs_noise_input: float = 0.03,\n",
    "        abs_noise_output: float = 10.0,\n",
    "        rel_noise_output: float = 0.2,\n",
    "        threshold_for_abs_noise: float = 200,\n",
    "        use_different_zones_for_output: bool = True,\n",
    "    ) -> \"RosenbrockContainer\":\n",
    "        if use_different_zones_for_output:\n",
    "            output_bound_domain_param = BoundsDomainBoxParameterPerValueInterval(\n",
    "                [\n",
    "                    (\n",
    "                        -float(\"inf\"),\n",
    "                        -threshold_for_abs_noise,\n",
    "                        BoundsDomainBoxParameter(rel_noise=rel_noise_output, use_relative=True),\n",
    "                    ),\n",
    "                    (\n",
    "                        -threshold_for_abs_noise,\n",
    "                        threshold_for_abs_noise,\n",
    "                        BoundsDomainBoxParameter(abs_noise=abs_noise_output, use_relative=False),\n",
    "                    ),\n",
    "                    (\n",
    "                        threshold_for_abs_noise,\n",
    "                        float(\"inf\"),\n",
    "                        BoundsDomainBoxParameter(rel_noise=rel_noise_output, use_relative=True),\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            output_bound_domain_param = BoundsDomainBoxParameter(abs_noise=abs_noise_output, use_relative=False)\n",
    "        stability_property = StabilityProperty(\n",
    "            input_bound_domain_param=BoundsDomainBoxParameter(abs_noise=abs_noise_input, use_relative=False),\n",
    "            output_bound_domain_param=output_bound_domain_param,\n",
    "        )\n",
    "        return RosenbrockContainer(tag_id=\"rosenbrock\", model=model, stability_property=stability_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ccacfa-814f-4a1a-b58f-cbad8647f26e",
   "metadata": {},
   "source": [
    "To create the output property, we make use of the ```BoundsDomainBoxParameterPerValueInterval``` class, allowing to define different output properties by interval of values. \n",
    "For e.g, \n",
    "```python\n",
    "\n",
    "(-float(\"inf\"), -threshold_for_abs_noise, BoundsDomainBoxParameter(rel_noise=rel_noise_output, use_relative=True))\n",
    "```\n",
    "means that if the expected value is between $-\\infty$ and  ```-threshold_for_abs_noise```, then the output property will use a relative noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872b103-60b8-4a16-bb1f-8a190b2b6668",
   "metadata": {},
   "source": [
    "#### Verification pipeline definition\n",
    "\n",
    "The verification pipeline is built from a sequence of individual blocks of verification that are executed on the remaining test points for which the stability property has not been assessed yet (See e.g., Figure 1 of [Airobas](https://arxiv.org/pdf/2401.06821)'s paper).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from airobas.blocks_hub.adv_block import CleverHansMultiIndexAdvBlock\n",
    "from airobas.blocks_hub.decomon_block import DecomonBlock\n",
    "from airobas.blocks_hub.marabou_block import MarabouBlock\n",
    "from airobas.verif_pipeline import (\n",
    "    BoundsDomainBoxParameter,\n",
    "    BoundsDomainBoxParameterPerValueInterval,\n",
    "    ProblemContainer,\n",
    "    StabilityProperty,\n",
    "    StatusVerif,\n",
    "    compute_bounds,\n",
    "    full_verification_pipeline,\n",
    ")\n",
    "\n",
    "container = RosenbrockContainer.create_rosenbrock_container(\n",
    "    model,\n",
    "    abs_noise_input=0.03,\n",
    "    abs_noise_output=20,\n",
    "    rel_noise_output=0.1,\n",
    "    threshold_for_abs_noise=200,\n",
    "    use_different_zones_for_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37513d37",
   "metadata": {},
   "source": [
    "Let's first build a verification pipeline consisting in only an adversarial attack generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6157a-d6e3-4887-8f87-a4a99d03cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    (\n",
    "        CleverHansMultiIndexAdvBlock,\n",
    "        {\"list_params_adv_block\": [{\"index_target\": i, \"attack_up\": True, \"fgs\": True} for i in range(yt_g.shape[1])]},\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b54f66-561e-4e5c-b8d3-a754c37f1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "global_verif = full_verification_pipeline(\n",
    "    problem=container,\n",
    "    input_points=xtest_g,\n",
    "    output_points=y_pred,  # or ytest if you target ground truth\n",
    "    blocks_verifier=blocks,\n",
    "    verbose=True,\n",
    ")\n",
    "t2 = time.perf_counter()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96fca4-173d-49ac-8625-468bdf0344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airobas.verif_pipeline import StatusVerif\n",
    "\n",
    "print(np.sum(global_verif.status == StatusVerif.VERIFIED), \" verified points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.VIOLATED), \" violated points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.TIMEOUT), \" timeout points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.UNKNOWN), \" unknown points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b662c",
   "metadata": {},
   "source": [
    "We observe that the adversarial attack brick allows to identify test points whose stability property is disproven. It does not procure any robustness guarantee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6496f24",
   "metadata": {},
   "source": [
    "Let's now add a layer of abstract interpretation-based incomplete formal verification in order to derive fast verification guarantees for a fraction of the test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb77ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    (\n",
    "        CleverHansMultiIndexAdvBlock,\n",
    "        {\"list_params_adv_block\": [{\"index_target\": i, \"attack_up\": True, \"fgs\": True} for i in range(yt_g.shape[1])]},\n",
    "    )\n",
    "]\n",
    "blocks += [(DecomonBlock, {})]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "global_verif = full_verification_pipeline(\n",
    "    problem=container,\n",
    "    input_points=xtest_g,\n",
    "    output_points=y_pred,  # or ytest if you target ground truth\n",
    "    blocks_verifier=blocks,\n",
    "    verbose=True,\n",
    ")\n",
    "t2 = time.perf_counter()\n",
    "clear_output()\n",
    "\n",
    "from airobas.verif_pipeline import StatusVerif\n",
    "\n",
    "print(np.sum(global_verif.status == StatusVerif.VERIFIED), \" verified points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.VIOLATED), \" violated points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.TIMEOUT), \" timeout points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.UNKNOWN), \" unknown points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09686395",
   "metadata": {},
   "source": [
    "We observe that the incomplete formal verification allows to provide robustness guarantee for a number of test points on top of the non-stability cases identified by the adversarial attack generation alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5466b9e7",
   "metadata": {},
   "source": [
    "Let's finally build a verification pipeline consisting in:\n",
    "\n",
    "- a first step of adversarial attack generation, followed by\n",
    "- an abstract verification method step in order to converge on verification guarantees for a fraction of the test points and \n",
    "- a complete/exact method step based on the Satisfiability modulo theory using [Marabou](https://github.com/NeuralNetworkVerification/Marabou)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    (\n",
    "        CleverHansMultiIndexAdvBlock,\n",
    "        {\"list_params_adv_block\": [{\"index_target\": i, \"attack_up\": True, \"fgs\": True} for i in range(yt_g.shape[1])]},\n",
    "    )\n",
    "]\n",
    "blocks += [(DecomonBlock, {}), (MarabouBlock, {\"time_out\": 100})]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "global_verif = full_verification_pipeline(\n",
    "    problem=container,\n",
    "    input_points=xtest_g,\n",
    "    output_points=y_pred,  # or ytest if you target ground truth\n",
    "    blocks_verifier=blocks,\n",
    "    verbose=True,\n",
    ")\n",
    "t2 = time.perf_counter()\n",
    "clear_output()\n",
    "\n",
    "from airobas.verif_pipeline import StatusVerif\n",
    "\n",
    "print(np.sum(global_verif.status == StatusVerif.VERIFIED), \" verified points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.VIOLATED), \" violated points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.TIMEOUT), \" timeout points\")\n",
    "print(np.sum(global_verif.status == StatusVerif.UNKNOWN), \" unknown points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6ff1a-2fe1-44ad-a801-21d924c79fbc",
   "metadata": {},
   "source": [
    "The verification is here complete with all test points having been evaluated and labeled as stable/non-stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d61eaf-4126-4305-9e92-82ce5d65a70f",
   "metadata": {},
   "source": [
    "Let's now look at the details on how which method of the pipeline was able to conclude on a given test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb92f0a-6199-477c-b29e-51fd09baaa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = np.array(global_verif.methods)\n",
    "index_that_concluded = global_verif.index_block_that_concluded\n",
    "methods_concluded = methods[index_that_concluded]\n",
    "# Count the unique values and their counts\n",
    "unique_values, counts = np.unique(methods_concluded, return_counts=True)\n",
    "# Print the results\n",
    "print(\"Methods: \", unique_values)\n",
    "print(\"Points where the methods concluded (nb_met1, nb_met2, nb_met3) : \", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff6134-57be-407e-80df-fac21bdd058e",
   "metadata": {},
   "source": [
    "In this final experiment: \n",
    "- the adversarial attack brick was able to find counter examples for nb_met1 points out of 2000 test points. (2000-nb_met1)) remain to be assessed.\n",
    "- decomon (abstract interpretation) concluded on nb_met2 test points. 2000-nb_met1-nb_met2 remain to be assessed.\n",
    "- The Marabou solver concludes on the last nb_met3 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f0874-e895-4dfa-8b98-727b79da8515",
   "metadata": {},
   "source": [
    "#### Visualisation of non-robust test points\n",
    "In this final section, we propose an additional visualisation in 2d of potential adversarial attacks.\n",
    "If a given point $(x1,x2)$ has been successfully attacked, we focus on a zone $[x=x1, y\\in [x2-\\delta, x2+\\delta]]$. For different values of $y$ discretized between $x2-\\delta$ and $x2+\\delta$, we can compute and plot : \n",
    "- the expected output bounds computed considering our input perturbation domain\n",
    "-  bounds found by abstract interpretation\n",
    "-  ground truth and actual prediction of the model.\n",
    "- Finally we draw a cross where the y-axis value is the output value of the found adversarial attack and we annotate the input coordinate of the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657b621-8eb2-4f74-b1a0-8bd46c5775a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from decomon.models import clone\n",
    "\n",
    "indexes = np.nonzero(global_verif.status == StatusVerif.VIOLATED)\n",
    "cnt_x = np.array([x for x in global_verif.inputs if x is not None])\n",
    "cnt_y = np.array(\n",
    "    [global_verif.outputs[i] for i in range(len(global_verif.outputs)) if global_verif.outputs[i] is not None]\n",
    ")\n",
    "y_exp_min, y_exp_max = compute_bounds(container.stability_property, y_pred, is_input=False)\n",
    "decomon_model = clone(model)\n",
    "for index_counter_example in range(min(cnt_x.shape[0], 20)):\n",
    "    original_point = xtest_g[indexes[0][index_counter_example]]\n",
    "    # x_val = cnt_x[index_counter_example, 0]\n",
    "    x_val = original_point[0]\n",
    "    y_val = original_point[1]\n",
    "    expected_value = fun(np.array([original_point]))\n",
    "    found_value = cnt_y[index_counter_example]\n",
    "    y = np.linspace(max(-2, y_val - 0.2), min(2, y_val + 0.2), 100)\n",
    "    vals = np.array([[x_val, yi] for yi in y])\n",
    "    x_min_, x_max_ = compute_bounds(container.stability_property, vals, is_input=True)\n",
    "    box = np.concatenate([x_min_[:, None], x_max_[:, None]], 1)\n",
    "    y_up_, y_low_ = decomon_model.predict(box)\n",
    "    ground_truth = fun(vals)\n",
    "    output_property = model.predict(vals)\n",
    "    y_min_, y_max_ = compute_bounds(container.stability_property, output_property, is_input=False)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.plot(y, ground_truth, color=\"blue\", label=\"ground truth\")\n",
    "    ax.plot(y, output_property, color=\"green\", label=\"surrogate\")\n",
    "\n",
    "    ax.plot(y, y_min_, color=\"orange\", linestyle=\"--\", label=\"lower bound stability\")\n",
    "    ax.plot(y, y_max_, color=\"red\", linestyle=\"--\", label=\"upper bound stability\")\n",
    "\n",
    "    ax.plot(y, y_low_, color=\"orange\", label=\"lower bound decomon\")\n",
    "    ax.plot(y, y_up_, color=\"red\", label=\"upper bound decomon\")\n",
    "\n",
    "    ax.scatter([y_val], [found_value], marker=\"x\", s=500)\n",
    "    ax.annotate(\n",
    "        f\"\"\"\n",
    "                coor cnt example = ({cnt_x[index_counter_example][0]:.3g}, {cnt_x[index_counter_example][1]:.3g})\n",
    "                coor orig point = ({x_val:.3g}, {y_val:.3g})\n",
    "                \"\"\",\n",
    "        (y_val, found_value),\n",
    "        xytext=(0, 10),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.\", fc=\"blue\", ec=\"black\", alpha=0.3),\n",
    "    )\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    ax.set_title(f\"Slice around counter example, x1={x_val}\")\n",
    "    ax.set_xlabel(\"x2\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(image_dump_folder, f\"cnt_example_{index_counter_example}.png\"))\n",
    "\n",
    "    if index_counter_example != 5:\n",
    "        plt.close(fig)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df4262-b702-47b8-82d7-4206e965fcf9",
   "metadata": {},
   "source": [
    "The ```images/``` folder contains some examples of visualisation of counter examples.\n",
    "\n",
    "Examples of counter examples:\n",
    "\n",
    "![im](rosenbrock_images/cnt_example_0.png)\n",
    "![im](rosenbrock_images/cnt_example_1.png)\n",
    "![im](rosenbrock_images/cnt_example_2.png)\n",
    "![im](rosenbrock_images/cnt_example_3.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
